<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Conqueror712">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://conqueror712.github.io/post/dl-cnn.html"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="前言：本篇内容记录笔者学习深度学习的学习过程，如果你有任何想询问的问题，欢迎在以下任何平台提问！ 参考书：《动手学深度学习》  个人博客：https:&#x2F;&#x2F;conqueror712.github.io&#x2F; 知乎：https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;soeur712&#x2F;posts  Bilibili：https:&#x2F;&#x2F;space.bilibili.com&#x2F;57089326  掘金：ht">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习 - Ep4 - 卷积神经网络丨学习记录">
<meta property="og:url" content="https://conqueror712.github.io/post/DL-CNN.html">
<meta property="og:site_name" content="落雨乄天珀夜">
<meta property="og:description" content="前言：本篇内容记录笔者学习深度学习的学习过程，如果你有任何想询问的问题，欢迎在以下任何平台提问！ 参考书：《动手学深度学习》  个人博客：https:&#x2F;&#x2F;conqueror712.github.io&#x2F; 知乎：https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;soeur712&#x2F;posts  Bilibili：https:&#x2F;&#x2F;space.bilibili.com&#x2F;57089326  掘金：ht">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdnjson.com/images/2023/04/08/image713e2a24b5495899.png">
<meta property="og:image" content="https://cdnjson.com/images/2023/04/19/image.png">
<meta property="og:image" content="https://cdnjson.com/images/2023/04/19/imagecd0d3843ecbae19a.png">
<meta property="og:image" content="https://cdnjson.com/images/2023/04/19/image698e0910fe9a35f9.png">
<meta property="og:image" content="https://cdnjson.com/images/2023/04/19/image2d706cc4ae16c640.png">
<meta property="og:image" content="https://img.picgo.net/2023/04/19/image01b296e555bb4e42.png">
<meta property="og:image" content="https://img.picgo.net/2023/04/19/image7fe28db16e3136e3.png">
<meta property="og:image" content="https://img.picgo.net/2023/04/19/image92cfb05af2c1888f.png">
<meta property="article:published_time" content="2023-04-08T11:48:55.000Z">
<meta property="article:modified_time" content="2023-04-23T03:07:54.906Z">
<meta property="article:author" content="落雨乄天珀夜">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdnjson.com/images/2023/04/08/image713e2a24b5495899.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/redefine-favicon.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/redefine-favicon.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/redefine-favicon.svg">
    <!--- Page Info-->
    
    <title>
        
            深度学习 - Ep4 - 卷积神经网络丨学习记录 -
        
        落雨乄天珀夜的主页
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/css/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"conqueror712.github.io","root":"/","language":"zh-CN"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"Conqueror712's Homepage","subtitle":{"text":[],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/Conqueror712","jutjin":"https://juejin.cn/user/1297878069809725/posts","email":"Conqueror712@bupt.edu.cn"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.4.4","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":null},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2022/8/17 11:45:14"};
    Global.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="落雨乄天珀夜" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="https://conqueror712.github.io/">
                
                落雨乄天珀夜的主页
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                
                
                <img src="https://picx.zhimg.com/v2-b7e4abd246f59a7ced519e2deebc810a_1440w.jpg?source=172ae18b" alt="深度学习 - Ep4 - 卷积神经网络丨学习记录" class="max-w-none"/>
                
                <h1 class="article-title-cover">深度学习 - Ep4 - 卷积神经网络丨学习记录</h1>
            
            </div>
            
                    
        
        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/redefine-avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Conqueror712</span>
                        
                            <span class="author-label">Lv4</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-04-08 19:48:55</span>
        <span class="mobile">2023-04-08 19:48:55</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-04-23 11:07:54</span>
            <span class="mobile">2023-04-23 11:07:54</span>
            <span class="hover-info">更新</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>本篇内容记录笔者学习深度学习的学习过程，如果你有任何想询问的问题，欢迎在以下任何平台提问！</p>
<p>参考书：《动手学深度学习》</p>
<blockquote>
<p>个人博客：<a href="https://conqueror712.github.io/">https://conqueror712.github.io/</a></p>
<p>知乎：<a class="link"   target="_blank" rel="noopener" href="https://www.zhihu.com/people/soeur712/posts" >https://www.zhihu.com/people/soeur712/posts <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>Bilibili：<a class="link"   target="_blank" rel="noopener" href="https://space.bilibili.com/57089326" >https://space.bilibili.com/57089326 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>掘金：<a class="link"   target="_blank" rel="noopener" href="https://juejin.cn/user/1297878069809725/posts" >https://juejin.cn/user/1297878069809725/posts <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
</blockquote>
<hr>
<h1 id="从全连接层到卷积："><a href="#从全连接层到卷积：" class="headerlink" title="从全连接层到卷积："></a>从全连接层到卷积：</h1><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdnjson.com/images/2023/04/08/image713e2a24b5495899.png"
                      alt="avatar"
                ></p>
<ul>
<li>图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。</li>
<li>局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。</li>
<li>在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。</li>
<li>卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。</li>
<li>多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。</li>
</ul>
<hr>
<h1 id="图像卷积："><a href="#图像卷积：" class="headerlink" title="图像卷积："></a>图像卷积：</h1><h2 id="互相关运算："><a href="#互相关运算：" class="headerlink" title="互相关运算："></a>互相关运算：</h2><p>卷积神经网络的设计更多的用于图像数据，</p>
<p>而严格来说，”卷积”这个词用的有点问题，事实上，它所做的运算是<strong>互相关运算</strong>而非卷积运算。</p>
<p>在卷积层中，<strong>输入张量和核张量通过互相关运算产生输出张量</strong>。</p>
<p>我们以一个例子来说明，话不多说，上图：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdnjson.com/images/2023/04/19/image.png"
                      alt="avatar"
                ></p>
<hr>
<h2 id="卷积层和卷积核的区别："><a href="#卷积层和卷积核的区别：" class="headerlink" title="卷积层和卷积核的区别："></a>卷积层和卷积核的区别：</h2><ul>
<li>卷积层是深度神经网络中的一种基本层级结构，其目的是从输入数据中提取有用的特征。</li>
<li><strong>卷积层由多个卷积核组成</strong>，每个卷积核用于对输入数据进行卷积操作，从而生成输出特征图。</li>
</ul>
<p>卷积核是卷积层中的一个重要参数，它定义了卷积操作的形式和卷积层的特征提取能力。</p>
<p>卷积核通常是一个小的、固定大小的矩阵，可以视为卷积运算中的滤波器。</p>
<p>卷积核中的每个元素都具有一定的权重，用于控制对输入数据中不同位置的响应。</p>
<p>在具体操作中，卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。</p>
<hr>
<h2 id="图像中目标的边缘检测："><a href="#图像中目标的边缘检测：" class="headerlink" title="图像中目标的边缘检测："></a>图像中目标的边缘检测：</h2><p>通过找到像素变化的位置，来检测图像中不同颜色的边缘。</p>
<p>举个例子（例子来源于《动手学深度学习》）：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">X</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure></div>

<p>我们构造一个高度为1、宽度为2的卷积核<code>K</code>。</p>
<p>当进行互相关运算时，<strong>如果水平相邻的两元素相同，则输出为零，否则输出为非零。</strong></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K = torch.tensor([[<span class="number">1.0</span>, -<span class="number">1.0</span>]])</span><br></pre></td></tr></table></figure></div>

<p>现在，我们对参数<code>X</code>（输入）和<code>K</code>（卷积核）执行互相关运算。 如下所示，输出<code>Y</code>中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘，其他情况的输出为0。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y = corr2d(X, K)</span><br><span class="line">Y</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure></div>

<p>现在我们将输入的二维图像转置，再进行如上的互相关运算。</p>
<p>其输出如下，之前检测到的垂直边缘消失了。 不出所料，这个卷积核<code>K</code><strong>只可以检测垂直边缘，无法检测水平边缘</strong>。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr2d(X.t(), K)</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="学习卷积核："><a href="#学习卷积核：" class="headerlink" title="学习卷积核："></a>学习卷积核：</h1><p>对于更复杂数值的卷积核或者连续的卷积层来说，我们就不太可能去手动设计滤波器了；</p>
<p>这时候就需要通过”学习”来构造适合的卷积核了。</p>
<p>先构造一个卷积层，并将其卷积核初始化为随机张量。</p>
<p>接下来，在每次迭代中，我们比较<code>Y</code>与卷积层输出的平方误差，然后计算梯度来更新卷积核。</p>
<p>一个例子：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核</span></span><br><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>,<span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），</span></span><br><span class="line"><span class="comment"># 其中批量大小和通道数都为1</span></span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line">lr = <span class="number">3e-2</span>  <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    Y_hat = conv2d(X)</span><br><span class="line">    l = (Y_hat - Y) ** <span class="number">2</span></span><br><span class="line">    conv2d.zero_grad()</span><br><span class="line">    l.<span class="built_in">sum</span>().backward()</span><br><span class="line">    <span class="comment"># 迭代卷积核</span></span><br><span class="line">    conv2d.weight.data[:] -= lr * conv2d.weight.grad</span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l.<span class="built_in">sum</span>():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></div>

<hr>
<ul>
<li>二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。</li>
<li>我们可以设计一个卷积核来检测图像的边缘。</li>
<li>我们可以从数据中学习卷积核的参数。</li>
<li>学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。</li>
<li>当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。</li>
</ul>
<hr>
<h1 id="填充和步幅："><a href="#填充和步幅：" class="headerlink" title="填充和步幅："></a>填充和步幅：</h1><h2 id="填充："><a href="#填充：" class="headerlink" title="填充："></a>填充：</h2><p>在应用多层卷积时，我们常常丢失边缘像素。</p>
<p>由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。</p>
<p>但随着我们应用许多连续卷积层，累积丢失的像素数就多了。</p>
<p>解决这个问题的简单方法即为<strong>填充（padding）</strong>：在输入图像的边界填充元素（通常填充元素是0）。</p>
<p>如下例，我们将3×3输入填充到5×5，那么它的输出就增加为4×4：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdnjson.com/images/2023/04/19/imagecd0d3843ecbae19a.png"
                      alt="avatar"
                ></p>
<hr>
<h2 id="步幅："><a href="#步幅：" class="headerlink" title="步幅："></a>步幅：</h2><p>在计算互相关时，卷积窗口从输入张量的左上角开始，向下、向右滑动。</p>
<p>在前面的例子中，我们默认每次滑动一个元素。</p>
<p>但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。</p>
<p>我们将每次滑动元素的数量称为<strong>步幅（stride）</strong>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdnjson.com/images/2023/04/19/image698e0910fe9a35f9.png"
                      alt="avatar"
                ></p>
<hr>
<ul>
<li>填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。</li>
<li>步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的$1&#x2F;n$（n是一个大于1的整数）。</li>
<li>填充和步幅可用于有效地调整数据的维度。</li>
</ul>
<hr>
<h1 id="多输入多输出通道："><a href="#多输入多输出通道：" class="headerlink" title="多输入多输出通道："></a>多输入多输出通道：</h1><h2 id="多输入通道："><a href="#多输入通道：" class="headerlink" title="多输入通道："></a>多输入通道：</h2><p>当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://cdnjson.com/images/2023/04/19/image2d706cc4ae16c640.png"
                      alt="avatar"
                ></p>
<hr>
<h2 id="多输出通道："><a href="#多输出通道：" class="headerlink" title="多输出通道："></a>多输出通道：</h2><p>在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。</p>
<p>直观地说，我们可以将每个通道看作对不同特征的响应。</p>
<p>而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。</p>
<p>因此，多输出通道并不仅是学习多个单通道的检测器。</p>
<hr>
<ul>
<li>多输入多输出通道可以用来扩展卷积层的模型。</li>
<li>当以每像素为基础应用时，1×1卷积层相当于<strong>全连接层</strong>。</li>
<li>1×1卷积层通常用于<strong>调整网络层的通道数量</strong>和<strong>控制模型复杂性</strong>。</li>
</ul>
<hr>
<h1 id="池化层："><a href="#池化层：" class="headerlink" title="池化层："></a>池化层：</h1><h2 id="最大池化层与平均池化层："><a href="#最大池化层与平均池化层：" class="headerlink" title="最大池化层与平均池化层："></a>最大池化层与平均池化层：</h2><p>池化层，也称汇聚层。</p>
<p>池化层的两个目的：</p>
<ul>
<li>降低卷积层对位置的敏感性；</li>
<li>降低对空间降采样表示的敏感性。</li>
</ul>
<p>与卷积层类似，池化层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口遍历的每个位置计算一个输出。</p>
<p>然而，不同于卷积层中的输入与卷积核之间的互相关计算，池化层不包含参数。</p>
<p>相反，池运算是确定性的，我们通常计算池化窗口中所有元素的最大值或平均值。</p>
<p>这些操作分别称为<em>最大池化层</em>（maximum pooling）和<em>平均池化层</em>（average pooling）。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img.picgo.net/2023/04/19/image01b296e555bb4e42.png"
                      alt="avatar"
                ></p>
<hr>
<h2 id="填充与步幅："><a href="#填充与步幅：" class="headerlink" title="填充与步幅："></a>填充与步幅：</h2><p>类似地，与卷积层一样，池化层也可以改变输出形状，通过改变填充和步幅。</p>
<hr>
<h2 id="多个通道："><a href="#多个通道：" class="headerlink" title="多个通道："></a>多个通道：</h2><p>在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。 这意味着汇聚层的输出通道数与输入通道数相同。</p>
<hr>
<ul>
<li>对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值。</li>
<li>汇聚层的主要优点之一是减轻卷积层对位置的过度敏感。</li>
<li>我们可以指定汇聚层的填充和步幅。</li>
<li>使用最大汇聚层以及大于1的步幅，可减少空间维度（如高度和宽度）。</li>
<li>汇聚层的输出通道数与输入通道数相同。</li>
</ul>
<hr>
<h1 id="卷积神经网络之——LeNet："><a href="#卷积神经网络之——LeNet：" class="headerlink" title="卷积神经网络之——LeNet："></a>卷积神经网络之——LeNet：</h1><p>LeNet是一种卷积神经网络，由Yann LeCun等人在1990年代提出，是卷积神经网络的开山鼻祖之一。</p>
<p>LeNet在当时被广泛应用于手写数字识别等任务，并为后来更复杂的卷积神经网络的设计奠定了基础。</p>
<p>虽然LeNet已经相对简单，但其基本的卷积神经网络结构已经被广泛应用于现代深度学习模型中。</p>
<p>因此，<strong>LeNet通常也被用作卷积神经网络的统称</strong>。</p>
<h2 id="LeNet："><a href="#LeNet：" class="headerlink" title="LeNet："></a>LeNet：</h2><p>总体来看，LeNet（LeNet-5）由两个部分组成：</p>
<ul>
<li>卷积编码器：由两个卷积层组成；</li>
<li>全连接层密集块：由三个全连接层组成。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img.picgo.net/2023/04/19/image7fe28db16e3136e3.png"
                      alt="avatar"
                ></p>
<p>简化版如下：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img.picgo.net/2023/04/19/image92cfb05af2c1888f.png"
                      alt="avatar" style="zoom: 67%;" 
                >

<ul>
<li>卷积神经网络（CNN）是一类使用卷积层的网络。</li>
<li>在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。</li>
<li>为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。</li>
<li>在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。</li>
<li>LeNet是最早发布的卷积神经网络之一。</li>
</ul>
<hr>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li><strong>标题:</strong> 深度学习 - Ep4 - 卷积神经网络丨学习记录</li>
        <li><strong>作者:</strong> Conqueror712</li>
        <li><strong>创建于
                :</strong> 2023-04-08 19:48:55</li>
        
            <li>
                <strong>更新于
                    :</strong> 2023-04-23 11:07:54
            </li>
        
        <li>
            <strong>链接:</strong> https://redefine.ohevan.com//post/DL-CNN.html
        </li>
        <li>
            <strong>
                版权声明:
            </strong>
            
            本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a> 进行许可。
            

        </li>
    </ul>
</div>

            </div>
        

        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/post/Neo4j-3.html"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">Neo4j - Ep3丨学习记录</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/post/Neo4j-2.html"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">Neo4j - Ep2丨学习记录</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
            <div class="comment-container">
                <div class="comments-container pjax">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;评论
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-swup-reload-script>
        import { init } from 'https://evan.beee.top/js/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

            </div>
        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">深度学习 - Ep4 - 卷积神经网络丨学习记录</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80%EF%BC%9A"><span class="nav-text">前言：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF%EF%BC%9A"><span class="nav-text">从全连接层到卷积：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%EF%BC%9A"><span class="nav-text">图像卷积：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97%EF%BC%9A"><span class="nav-text">互相关运算：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9A"><span class="nav-text">卷积层和卷积核的区别：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E4%B8%AD%E7%9B%AE%E6%A0%87%E7%9A%84%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%EF%BC%9A"><span class="nav-text">图像中目标的边缘检测：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E5%8D%B7%E7%A7%AF%E6%A0%B8%EF%BC%9A"><span class="nav-text">学习卷积核：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85%EF%BC%9A"><span class="nav-text">填充和步幅：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A1%AB%E5%85%85%EF%BC%9A"><span class="nav-text">填充：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A5%E5%B9%85%EF%BC%9A"><span class="nav-text">步幅：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%EF%BC%9A"><span class="nav-text">多输入多输出通道：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93%EF%BC%9A"><span class="nav-text">多输入通道：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%EF%BC%9A"><span class="nav-text">多输出通道：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%9A"><span class="nav-text">池化层：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E5%B1%82%E4%B8%8E%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%9A"><span class="nav-text">最大池化层与平均池化层：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A1%AB%E5%85%85%E4%B8%8E%E6%AD%A5%E5%B9%85%EF%BC%9A"><span class="nav-text">填充与步幅：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E4%B8%AA%E9%80%9A%E9%81%93%EF%BC%9A"><span class="nav-text">多个通道：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E2%80%94%E2%80%94LeNet%EF%BC%9A"><span class="nav-text">卷积神经网络之——LeNet：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet%EF%BC%9A"><span class="nav-text">LeNet：</span></a></li></ol></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Conqueror712</a>
        </div>
        
            <script data-swup-reload-script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">访问人数</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">总访问量</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a> 驱动</span>
            <span class="text-sm lg:block">主题&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.4.4</a></span>
        </div>
        
        
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex justify-center items-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
        ],
        containers: ["#swup"],
    });

    swup.hooks.on("page:view", () => {
        Global.refresh();
    });

    // if (document.readyState === "complete") {
    //
    // } else {
    //     document.addEventListener("DOMContentLoaded", () => init());
    // }
</script>






<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>





    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


</body>
</html>
